{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c6a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ortools\n",
      "  Downloading ortools-9.9.3963-cp310-cp310-macosx_11_0_arm64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/yuanshan/anaconda3/lib/python3.10/site-packages (from ortools) (1.23.5)\n",
      "Collecting pandas>=2.0.0\n",
      "  Downloading pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=4.25.3\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl (404 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.0/404.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=2.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting immutabledict>=3.0.0\n",
      "  Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yuanshan/anaconda3/lib/python3.10/site-packages (from pandas>=2.0.0->ortools) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yuanshan/anaconda3/lib/python3.10/site-packages (from pandas>=2.0.0->ortools) (2.8.2)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/yuanshan/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools) (1.16.0)\n",
      "Installing collected packages: tzdata, protobuf, immutabledict, absl-py, pandas, ortools\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.3\n",
      "    Uninstalling protobuf-4.23.3:\n",
      "      Successfully uninstalled protobuf-4.23.3\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.4.0\n",
      "    Uninstalling absl-py-1.4.0:\n",
      "      Successfully uninstalled absl-py-1.4.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-macos 2.13.0rc2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 immutabledict-4.2.0 ortools-9.9.3963 pandas-2.2.2 protobuf-5.26.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ortools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98122822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ortools.graph.python import max_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d63a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a SimpleMaxFlow solver.\n",
    "smf = max_flow.SimpleMaxFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51906b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three parallel arrays: start_nodes, end_nodes, and the capacities\n",
    "# between each pair. For instance, the arc from node 0 to node 1 has a\n",
    "# capacity of 20.\n",
    "start_nodes = np.array([0, 0, 0, 1, 1, 2, 2, 3, 3])\n",
    "end_nodes = np.array([1, 2, 3, 2, 4, 3, 4, 2, 4])\n",
    "capacities = np.array([20, 30, 10, 40, 30, 10, 20, 5, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e805db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add arcs in bulk.\n",
    "#   note: we could have used add_arc_with_capacity(start, end, capacity)\n",
    "all_arcs = smf.add_arcs_with_capacity(start_nodes, end_nodes, capacities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076d684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum flow between node 0 and node 4.\n",
    "status = smf.solve(0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749a46be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max flow: 60\n",
      "\n",
      " Arc    Flow / Capacity\n",
      "0 / 1    20  /  20\n",
      "0 / 2    30  /  30\n",
      "0 / 3    10  /  10\n",
      "1 / 2     0  /  40\n",
      "1 / 4    20  /  30\n",
      "2 / 3    10  /  10\n",
      "2 / 4    20  /  20\n",
      "3 / 2     0  /   5\n",
      "3 / 4    20  /  20\n",
      "Source side min-cut: [0]\n",
      "Sink side min-cut: [4, 1]\n"
     ]
    }
   ],
   "source": [
    "if status != smf.OPTIMAL:\n",
    "    print(\"There was an issue with the max flow input.\")\n",
    "    print(f\"Status: {status}\")\n",
    "    exit(1)\n",
    "print(\"Max flow:\", smf.optimal_flow())\n",
    "print(\"\")\n",
    "print(\" Arc    Flow / Capacity\")\n",
    "solution_flows = smf.flows(all_arcs)\n",
    "for arc, flow, capacity in zip(all_arcs, solution_flows, capacities):\n",
    "    print(f\"{smf.tail(arc)} / {smf.head(arc)}   {flow:3}  / {capacity:3}\")\n",
    "print(\"Source side min-cut:\", smf.get_source_side_min_cut())\n",
    "print(\"Sink side min-cut:\", smf.get_sink_side_min_cut())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54228779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max flow: 23\n",
      "\n",
      " Arc    Flow / Capacity\n",
      "0 / 1    12  /  16\n",
      "0 / 2    11  /  13\n",
      "1 / 3    12  /  12\n",
      "2 / 1     0  /   4\n",
      "2 / 4    11  /  14\n",
      "3 / 2     0  /   9\n",
      "3 / 5    19  /  20\n",
      "4 / 3     7  /   7\n",
      "4 / 5     4  /   4\n",
      "Source side min-cut: [0, 1, 2, 4]\n",
      "Sink side min-cut: [5, 3]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a SimpleMaxFlow solver.\n",
    "smf = max_flow.SimpleMaxFlow()\n",
    "\n",
    "# Define three parallel arrays: start_nodes, end_nodes, and the capacities\n",
    "# between each pair. \n",
    "start_nodes = np.array([0, 0, 1, 2, 2, 3, 3, 4, 4])\n",
    "end_nodes = np.array([1, 2, 3, 1, 4, 2, 5, 3, 5])\n",
    "capacities = np.array([16, 13, 12, 4, 14, 9, 20, 7, 4])\n",
    "\n",
    "# Add arcs in bulk.\n",
    "#   note: we could have used add_arc_with_capacity(start, end, capacity)\n",
    "all_arcs = smf.add_arcs_with_capacity(start_nodes, end_nodes, capacities)\n",
    "\n",
    "# Find the maximum flow.\n",
    "status = smf.solve(0, 5)\n",
    "\n",
    "if status != smf.OPTIMAL:\n",
    "    print(\"There was an issue with the max flow input.\")\n",
    "    print(f\"Status: {status}\")\n",
    "    exit(1)\n",
    "print(\"Max flow:\", smf.optimal_flow())\n",
    "print(\"\")\n",
    "print(\" Arc    Flow / Capacity\")\n",
    "solution_flows = smf.flows(all_arcs)\n",
    "for arc, flow, capacity in zip(all_arcs, solution_flows, capacities):\n",
    "    print(f\"{smf.tail(arc)} / {smf.head(arc)}   {flow:3}  / {capacity:3}\")\n",
    "print(\"Source side min-cut:\", smf.get_source_side_min_cut())\n",
    "print(\"Sink side min-cut:\", smf.get_sink_side_min_cut())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da61b764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max flow: 14\n",
      "\n",
      " Arc    Flow / Capacity\n",
      "0 / 1    10  /  16\n",
      "0 / 2     4  /  13\n",
      "6 / 3    10  /  12\n",
      "7 / 1     0  /   4\n",
      "7 / 4     4  /  14\n",
      "8 / 2     0  /   9\n",
      "8 / 5    10  /  20\n",
      "9 / 3     0  /   7\n",
      "9 / 5     4  /   4\n",
      "1 / 6    10  /  10\n",
      "2 / 7     4  /  10\n",
      "3 / 8    10  /  10\n",
      "4 / 9     4  /  10\n",
      "Source side min-cut: [0, 1, 2, 7, 4, 9, 3, 6]\n",
      "Sink side min-cut: [5, 8]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a SimpleMaxFlow solver.\n",
    "smf = max_flow.SimpleMaxFlow()\n",
    "\n",
    "# Define three parallel arrays: start_nodes, end_nodes, and the capacities\n",
    "# between each pair.\n",
    "start_nodes = np.array([0, 0, 6, 7, 7, 8, 8, 9, 9, 1, 2, 3, 4])\n",
    "end_nodes = np.array([1, 2, 3, 1, 4, 2, 5, 3, 5, 6, 7, 8, 9])\n",
    "capacities = np.array([16, 13, 12, 4, 14, 9, 20, 7, 4, 10, 10, 10, 10])\n",
    "\n",
    "# Add arcs in bulk.\n",
    "#   note: we could have used add_arc_with_capacity(start, end, capacity)\n",
    "all_arcs = smf.add_arcs_with_capacity(start_nodes, end_nodes, capacities)\n",
    "\n",
    "# Find the maximum flow.\n",
    "status = smf.solve(0, 5)\n",
    "\n",
    "if status != smf.OPTIMAL:\n",
    "    print(\"There was an issue with the max flow input.\")\n",
    "    print(f\"Status: {status}\")\n",
    "    exit(1)\n",
    "print(\"Max flow:\", smf.optimal_flow())\n",
    "print(\"\")\n",
    "print(\" Arc    Flow / Capacity\")\n",
    "solution_flows = smf.flows(all_arcs)\n",
    "for arc, flow, capacity in zip(all_arcs, solution_flows, capacities):\n",
    "    print(f\"{smf.tail(arc)} / {smf.head(arc)}   {flow:3}  / {capacity:3}\")\n",
    "print(\"Source side min-cut:\", smf.get_source_side_min_cut())\n",
    "print(\"Sink side min-cut:\", smf.get_sink_side_min_cut())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a859e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
